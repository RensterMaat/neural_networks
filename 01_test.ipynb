{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import accumulate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Tensor():\n",
    "    def __init__(self, value, requires_grad=True):\n",
    "        self.value = np.array(value, dtype=float)\n",
    "        self.requires_grad = requires_grad\n",
    "\n",
    "        if requires_grad:\n",
    "            self.grad = np.zeros(self.value.shape)\n",
    "        \n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        if self.requires_grad:\n",
    "            self.grad += accumulated_gradient\n",
    "\n",
    "    def __add__(self, b):\n",
    "        return Add(self, b)\n",
    "\n",
    "    def __sub__(self, b):\n",
    "        return Add(self, Neg(b))\n",
    "\n",
    "    def __mul__(self, b):\n",
    "        return Mul(self, b)\n",
    "\n",
    "    def __truediv__(self, b):\n",
    "        return Mul(self,  b) #** Tensor(-1)\n",
    "\n",
    "    def __pow__(self, b):\n",
    "        return Pow(self, b)\n",
    "\n",
    "    def __matmul__(self, b):\n",
    "        return Dot(self, b)\n",
    "\n",
    "    def __gt__(self, b):\n",
    "        return Tensor(self.value > b.value, requires_grad=False)\n",
    "\n",
    "class Add(Tensor):\n",
    "    def __init__(self, a, b):\n",
    "        self.a, self.b = a, b\n",
    "        self.value = a.value + b.value\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "\n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(accumulated_gradient)\n",
    "        self.b.backwards(accumulated_gradient)\n",
    "\n",
    "class Neg(Tensor):\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "        self.value = -a.value\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "    \n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(-accumulated_gradient)\n",
    "\n",
    "class Mul(Tensor):\n",
    "    def __init__(self, a, b):\n",
    "        self.a, self.b = a, b\n",
    "        self.value = a.value * b.value\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "\n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(self.b.value * accumulated_gradient)\n",
    "        self.b.backwards(self.a.value * accumulated_gradient)\n",
    "\n",
    "class Pow(Tensor):\n",
    "    def __init__(self, a, b):\n",
    "        self.a, self.b = a, b\n",
    "        self.value = a.value ** b.value\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "\n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(self.b.value * self.a.value ** (self.b.value-1) * accumulated_gradient)\n",
    "        self.b.backwards(np.log(self.a.value) * self.a.value ** self.b.value * accumulated_gradient)\n",
    "\n",
    "class Dot(Tensor):\n",
    "    def __init__(self, a, b):\n",
    "        self.a, self.b = a, b\n",
    "        self.value = a.value @ b.value\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "\n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(accumulated_gradient @ self.b.value.T)\n",
    "        self.b.backwards(self.a.value.T @ accumulated_gradient)        \n",
    "\n",
    "class Sum(Tensor):\n",
    "    def __init__(self, a):\n",
    "        self.a = a\n",
    "        self.value = sum(a.value)\n",
    "        self.grad = np.zeros(self.value.shape)\n",
    "\n",
    "    def backwards(self, accumulated_gradient=None):\n",
    "        self.a.backwards(np.ones(self.a.shape) * accumulated_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tensor([[1],[2]])\n",
    "\n",
    "m1 = Tensor(np.random.rand(3,2))\n",
    "\n",
    "m2 = Tensor(np.random.rand(1,3))\n",
    "\n",
    "target = Tensor(60,requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rens\\AppData\\Local\\Temp\\ipykernel_9952\\516360292.py:75: RuntimeWarning: invalid value encountered in log\n",
      "  self.b.backwards(np.log(self.a.value) * self.a.value ** self.b.value * accumulated_gradient)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "\n",
    "losses = []\n",
    "for ix in range(100):\n",
    "    h = m1 @ x\n",
    "    h = h * (h > Tensor(0))\n",
    "    y = m2 @ h\n",
    "\n",
    "    loss = ((y - target) ** Tensor(2,requires_grad=False))\n",
    "\n",
    "    loss = loss / Tensor(5, requires_grad=False)\n",
    "\n",
    "    losses.append(loss.value)\n",
    "\n",
    "    loss.backwards(np.ones(loss.value.shape))\n",
    "\n",
    "    for m in [m1,m2]:\n",
    "        m.value = m.value - lr * m.grad\n",
    "        m.grad = np.zeros(m.value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[17425.28875932]]),\n",
       " array([[17196.77262158]]),\n",
       " array([[16924.75707715]]),\n",
       " array([[16594.97252537]]),\n",
       " array([[16191.75107758]]),\n",
       " array([[15698.16163379]]),\n",
       " array([[15096.62564263]]),\n",
       " array([[14370.2112265]]),\n",
       " array([[13504.80490521]]),\n",
       " array([[12492.26831382]]),\n",
       " array([[11334.43438565]]),\n",
       " array([[10047.33446672]]),\n",
       " array([[8664.42262022]]),\n",
       " array([[7237.02639238]]),\n",
       " array([[5830.2941866]]),\n",
       " array([[4514.04734908]]),\n",
       " array([[3350.1893752]]),\n",
       " array([[2380.65353056]]),\n",
       " array([[1620.52777029]]),\n",
       " array([[1058.94400539]]),\n",
       " array([[666.61134717]]),\n",
       " array([[406.06622139]]),\n",
       " array([[240.53568565]]),\n",
       " array([[139.23383242]]),\n",
       " array([[79.11458107]]),\n",
       " array([[44.302765]]),\n",
       " array([[24.53032516]]),\n",
       " array([[13.46590378]]),\n",
       " array([[7.34418466]]),\n",
       " array([[3.98599125]]),\n",
       " array([[2.15553083]]),\n",
       " array([[1.16253217]]),\n",
       " array([[0.62573959]]),\n",
       " array([[0.33631569]]),\n",
       " array([[0.18056498]]),\n",
       " array([[0.09686723]]),\n",
       " array([[0.05193601]]),\n",
       " array([[0.02783401]]),\n",
       " array([[0.0149124]]),\n",
       " array([[0.00798768]]),\n",
       " array([[0.00427781]]),\n",
       " array([[0.0022907]]),\n",
       " array([[0.00122653]]),\n",
       " array([[0.00065668]]),\n",
       " array([[0.00035157]]),\n",
       " array([[0.00018822]]),\n",
       " array([[0.00010076]]),\n",
       " array([[5.39408617e-05]]),\n",
       " array([[2.88759742e-05]]),\n",
       " array([[1.54579197e-05]]),\n",
       " array([[8.27489046e-06]]),\n",
       " array([[4.42966745e-06]]),\n",
       " array([[2.37125513e-06]]),\n",
       " array([[1.2693582e-06]]),\n",
       " array([[6.79499573e-07]]),\n",
       " array([[3.63742052e-07]]),\n",
       " array([[1.94714076e-07]]),\n",
       " array([[1.04231941e-07]]),\n",
       " array([[5.57961249e-08]]),\n",
       " array([[2.98680631e-08]]),\n",
       " array([[1.59885818e-08]]),\n",
       " array([[8.55879691e-09]]),\n",
       " array([[4.58158159e-09]]),\n",
       " array([[2.45255115e-09]]),\n",
       " array([[1.31286685e-09]]),\n",
       " array([[7.02786259e-10]]),\n",
       " array([[3.76206088e-10]]),\n",
       " array([[2.01385576e-10]]),\n",
       " array([[1.07803011e-10]]),\n",
       " array([[5.77076534e-11]]),\n",
       " array([[3.08912821e-11]]),\n",
       " array([[1.65363038e-11]]),\n",
       " array([[8.85199074e-12]]),\n",
       " array([[4.738528e-12]]),\n",
       " array([[2.53656473e-12]]),\n",
       " array([[1.35783957e-12]]),\n",
       " array([[7.26860338e-13]]),\n",
       " array([[3.89093036e-13]]),\n",
       " array([[2.0828403e-13]]),\n",
       " array([[1.11495779e-13]]),\n",
       " array([[5.96844063e-14]]),\n",
       " array([[3.19494574e-14]]),\n",
       " array([[1.71027545e-14]]),\n",
       " array([[9.15521504e-15]]),\n",
       " array([[4.90084691e-15]]),\n",
       " array([[2.62345363e-15]]),\n",
       " array([[1.40435188e-15]]),\n",
       " array([[7.51758753e-16]]),\n",
       " array([[4.02420972e-16]]),\n",
       " array([[2.15418879e-16]]),\n",
       " array([[1.15314985e-16]]),\n",
       " array([[6.1729112e-17]]),\n",
       " array([[3.30436137e-17]]),\n",
       " array([[1.76886378e-17]]),\n",
       " array([[9.46875886e-18]]),\n",
       " array([[5.06876751e-18]]),\n",
       " array([[2.71335662e-18]]),\n",
       " array([[1.45247072e-18]]),\n",
       " array([[7.77508377e-19]]),\n",
       " array([[4.16227559e-19]])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [2., 4.],\n",
       "       [3., 6.]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., 11., 17.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [11],\n",
       "       [17]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "febf68473bab6d033111f0bbfcdb01a5e43af7a2aa8031c222717ba26a5a8e95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
